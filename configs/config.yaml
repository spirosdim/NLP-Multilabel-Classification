general:
  cwdir: ${hydra:runtime.cwd}
dataset:
  test: 'data/test_set.csv'
  folds: 'data/train_5folds.csv'
  fold: 0
  label_names: ['ml', 'cs', 'ph', 'mth', 'bio', 'fin']
train:
  pre_model_name: distilbert-base-uncased
  learning_rate: 1e-4
  weight_decay: 1e-6
  p_dropout: 0.4
  warmup_percentage: 0.15
  batch_size: 32
  n_epochs: 8
  use_gpu: True
  model_dir: model
  show_bar: True
  max_token_len: 512
logs:
  log_project: nlp_project
  log_pr_name: preprints